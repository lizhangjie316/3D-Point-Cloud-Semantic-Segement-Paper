<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Deep Learning for 3D Point Clouds: A Survey](#deep-learning-for-3d-point-clouds-a-survey)
- [Abstract](#abstract)
- [1. INTRODUCTION](#1-introduction)
- [2 3D形状分类](#2-3d%E5%BD%A2%E7%8A%B6%E5%88%86%E7%B1%BB)
  - [2.1基于投影的网络](#21%E5%9F%BA%E4%BA%8E%E6%8A%95%E5%BD%B1%E7%9A%84%E7%BD%91%E7%BB%9C)
    - [2.1.1多视图表示](#211%E5%A4%9A%E8%A7%86%E5%9B%BE%E8%A1%A8%E7%A4%BA)
    - [2.1.2体素表示](#212%E4%BD%93%E7%B4%A0%E8%A1%A8%E7%A4%BA)
  - [2.2 基于点的网络](#22-%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E7%BD%91%E7%BB%9C)
    - [2.2.1逐点MLP网络](#221%E9%80%90%E7%82%B9mlp%E7%BD%91%E7%BB%9C)
    - [2.2.2 基于卷积的网络](#222-%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%9A%84%E7%BD%91%E7%BB%9C)
    - [2.2.3 基于图的网络](#223-%E5%9F%BA%E4%BA%8E%E5%9B%BE%E7%9A%84%E7%BD%91%E7%BB%9C)
    - [2.2.4 基于数据索引的网络](#224-%E5%9F%BA%E4%BA%8E%E6%95%B0%E6%8D%AE%E7%B4%A2%E5%BC%95%E7%9A%84%E7%BD%91%E7%BB%9C)
    - [2.2.5 其他网络](#225-%E5%85%B6%E4%BB%96%E7%BD%91%E7%BB%9C)
- [3 3D目标检测和跟踪](#3-3d%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%92%8C%E8%B7%9F%E8%B8%AA)
  - [3.1 3D对象检测](#31-3d%E5%AF%B9%E8%B1%A1%E6%A3%80%E6%B5%8B)
    - [3.1.1 基于区域提案的方法](#311-%E5%9F%BA%E4%BA%8E%E5%8C%BA%E5%9F%9F%E6%8F%90%E6%A1%88%E7%9A%84%E6%96%B9%E6%B3%95)
    - [3.1.2 single-shot方法](#312-single-shot%E6%96%B9%E6%B3%95)
  - [3.2 3D对象跟踪](#32-3d%E5%AF%B9%E8%B1%A1%E8%B7%9F%E8%B8%AA)
  - [3.3 3D场景流估计](#33-3d%E5%9C%BA%E6%99%AF%E6%B5%81%E4%BC%B0%E8%AE%A1)
  - [3.4 总结](#34-%E6%80%BB%E7%BB%93)
- [4 3D 点云分割](#4-3d-%E7%82%B9%E4%BA%91%E5%88%86%E5%89%B2)
  - [4.1 3D 语义分割](#41-3d-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2)
    - [4.1.1基于投影的网络](#411%E5%9F%BA%E4%BA%8E%E6%8A%95%E5%BD%B1%E7%9A%84%E7%BD%91%E7%BB%9C)
    - [4.1.2基于点的网络](#412%E5%9F%BA%E4%BA%8E%E7%82%B9%E7%9A%84%E7%BD%91%E7%BB%9C)
  - [4.2 实例分割](#42-%E5%AE%9E%E4%BE%8B%E5%88%86%E5%89%B2)
  - [4.3 零件分割](#43-%E9%9B%B6%E4%BB%B6%E5%88%86%E5%89%B2)
  - [4.4 总结](#44-%E6%80%BB%E7%BB%93)
- [5 总结](#5-%E6%80%BB%E7%BB%93)
- [REFERENCES](#references)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# Deep Learning for 3D Point Clouds: A Survey

Y ulan Guo∗, Hanyun Wang∗, Qingyong Hu∗, Hao Liu∗, Li Liu, and Mohammed Bennamoun  **2019.12**

---

[TOC]

---

# Abstract

​		点云学习由于其在计算机视觉、自动驾驶、机器人等领域的广泛应用，近年来受到越来越多的关注。深度学习作为人工智能领域的主流技术，已经成功地应用于解决各种二维视觉问题。然而，由于深度神经网络处理点云所面临的独特挑战，点云深度学习仍处于起步阶段。近年来，关于点云的深度学习已经蓬勃发展，人们提出了许多方法来解决这一领域的不同问题。为了促进未来的研究，本文对点云深度学习方法的最新进展进行了全面的综述。它包括三个主要任务，包括三维形状分类、三维目标检测和跟踪以及三维点云分割。它还提供了几个公开可用的数据集的比较结果，以及有洞察力的观察结果和鼓舞人心的未来研究方向。

**Index Terms**-深度学习、点云、3D数据、形状分类、对象检测、对象跟踪、场景流、实例分割、语义分割、场景理解

---

# 1. INTRODUCTION

​		随着3D采集技术的快速发展，3D传感器变得越来越容易获得，价格也越来越实惠，包括各种类型的3D扫描仪、激光雷达和RGB-D相机(如Kinect、RealSense和Apple  Depth相机)[1]。这些传感器采集的三维数据可以提供丰富的几何、形状和尺度信息[2]、[3]。3D数据与2D图像相辅相成，为更好地了解机器周围环境提供了机会。3D数据在不同领域有很多应用，包括自动驾驶、机器人、遥感、医疗和设计业[4]。

​		三维数据通常可以用不同的格式表示，包括深度图像、点云、网格和体积栅格。点云表示作为一种常用的表示格式，在三维空间中不需要任何离散化就可以保持原有的几何信息。因此，它是许多场景理解相关应用(如自动驾驶和机器人)的首选表示。近年来，深度学习技术在计算机视觉、语音识别、自然语言处理、生物信息学等领域占据主导地位。然而，三维点云的深度学习仍然面临着一些重大的挑战[5]，如数据集规模小、高维和三维点云的非结构化性质。在此基础上，重点分析了用于处理三维点云的深度学习方法。

​        点云的深度学习越来越受到人们的关注，特别是近五年来，点云的深度学习受到了越来越多的关注。还发布了几个公开可用的数据集，如ModelNet[6]、ShapeNet[7]、ScanNet[8]、Semanti3D[9]和Kitti  Vision Benchmark  Suite[10]。这些数据集进一步推动了三维点云深度学习的研究，越来越多的方法被提出来解决与点云处理相关的各种问题，包括三维形状分类、三维目标检测与跟踪、三维点云分割。关于3D数据的深度学习的调查也很少，例如[11]、[12]、[13]、[14]。然而，我们的论文是第一篇专门针对点云深度学习方法的论文。此外，本文还全面涵盖了分类、检测、跟踪和分割等不同的应用。三维点云现有深度学习方法的分类如图1所示。

![image-20200422112530030](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422112531.png)

​											             图1：三维点云深度学习方法的分类。

与已有文献相比，本文的主要贡献可以概括为：

1. 据我们所知，这是第一篇全面涵盖三维形状分类、三维目标检测与跟踪、三维点云分割等几个重要点云相关任务的深度学习方法的调查论文。
2. 与现有的综述[11]、[12]不同，我们特别关注3D点云的深度学习方法，而不是所有类型的3D数据。
3. 介绍了点云深度学习的最新进展。因此，它为读者提供了最先进的方法。4)提供了几个公开可用的数据集上现有方法的综合比较(例如，在表1、2、3、4中)，并给出了简要总结和有洞察力的讨论。

本文的结构如下。第二节对三维形状分类方法进行了综述。第3节提供了对于3D目标检测和跟踪对现有方法的概述。第四部分对点云分割方法进行了综述，包括语义分割、实例分割和部分分割。最后，第五部分对全文进行了总结。我们还提供了一个定期更新的项目页面： https://github.com/QingyongHu/SoTA-Point-Cloud.

# 2 3D形状分类
这些方法通常首先学习每个点的嵌入，然后使用聚合方法从整个点云中提取全局形状嵌入。最终，通过几个完全连接的层实现了分类。基于在每个点上执行特征学习的方式，现有的3D形状分类方法可以分为基于投影的网络和基于点的网络。图2说明了几种里程碑方法。

图2：3D形状分类网络的时间顺序概述。
基于投影的方法首先将非结构化的点云投影到中间的规则表示中，然后利用完善的2D或3D卷积实现形状分类。相反，基于点的方法可直接在原始点云上运行，而无需任何体素化或投影。基于点的方法不会造成明显的信息丢失，并且越来越受欢迎。 文中，作者主要关注基于点的网络，但为了完整起见，也很少包含基于投影的网络。

## 2.1基于投影的网络
这些方法将3D点云投影到不同的表示形式（例如多视图，体积表示）中，用于特征学习和形状分类。

### 2.1.1多视图表示
这些方法首先将3D对象投影到多个视图中，并提取相应的按视图方向的特征，然后融合这些特征以进行准确的对象识别。 如何将多个基于视图的特征聚合到一个可区分的全局表示中是一个关键挑战。 MVCNN [15]是一项开创性的工作，它只是将多视图特征最大池化为一个全局描述符。 但是，最大池化只能保留特定视图中的最大元素，会导致信息丢失。 MHBN [16]通过协调双线性池化整合了局部卷积特征，以生成紧凑的全局描述符。 杨等[17]首先利用关系网络来利用一组视图之间的相互关系（例如，区域-区域关系和视图-视图关系），然后将这些视图进行聚合以获得具有区别性的3D对象表示。 另外，还提出了其他几种方法[18]，[19]，[20]，[21]以提高识别精度。

### 2.1.2体素表示
早期方法通常在3D点云的体素表示基础上应用3D卷积神经网络（CNN）。 Daniel等[22]介绍了一种称为VoxNet的体积占用网络，以实现可靠的3D对象识别。 Wu等[6]提出了一种基于卷积深度信念的3D ShapeNet，以学习各种3D形状中点的分布。 3D形状通常由体素网格上二进制变量的概率分布表示。尽管已经实现了令人鼓舞的性能，但是这些方法无法很好地应用到密集的3D数据，因为计算和内存占用量会随着分辨率的增加而三次增长。为此，引入了分层而紧凑的图结构（例如八叉树）以减少这些方法的计算和存储成本。 OctNet [23]首先使用混合网格八叉树结构对点云进行分层划分，该结构代表沿规则网格具有几个浅八叉树的场景。使用位串表示对octree的结构进行有效编码，并通过简单的算法对每个体素的特征向量进行索引。 Wang等[24]提出了一种基于Octree的CNN用于3D形状分类。在最细的叶子八分位数中采样的3D模型的平均法线向量被馈送到网络中，并将3D-CNN应用于3D形状表面所占据的八分位数。与基于密集输入网格的基准网络相比，OctNet对于高分辨率点云所需的内存和运行时间要少得多。 Le等[25]提出了一种称为PointGrid的混合网络，该网络集成了点和网格表示，以进行有效的点云处理。在每个嵌入的体素网格单元中采样恒定数量的点，这使网络可以使用3D卷积提取几何细节。

![image-20200422231025922](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231027.png)

​														图2：3D形状分类网络的时序概述

## 2.2 基于点的网络

​		根据用于每个点的特征学习的网络体系结构，可以将这一类的方法分为逐点MLP，基于卷积，基于图，基于数据索引的网络和其他典型网络。

### 2.2.1逐点MLP网络
这些方法使用多个多层感知器（MLP）独立地对每个点建模，然后使用对称函数聚合全局特征，**如图3所示**。这些网络可以实现无序3D点云的置换不变性。但是，没有完全考虑3D点之间的几何关系。

![image-20200422231131820](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231133.png)

图3：PointNet的体系结构。 n表示输入点的数量，M表示每个点的学习特征尺寸。 在最大池化之后，整个点云的全局特征的维度也是M。
		作为一项开创性的工作，PointNet [5]通过几个MLP层学习逐点特征，并通过最大池化层提取全局形状特征。 使用几个MLP层获得分类分数。 Zaheer等[26]从理论上也证明了实现置换不变性的关键是对所有表示求和并应用非线性变换。 他们还为包括形状分类在内的各种应用设计了一种基本架构DeepSets [26]。
由于对于PointNet [5]中的每个点都是独立学习特征的，因此无法捕获点之间的局部结构信息。 因此，齐等[27]提出了一个层次网络PointNet ++来捕获每个点附近的精细几何结构。 作为PointNet ++层次结构的核心，其集合抽象级别由三层组成：采样层，分组层和PointNet层。 通过堆叠几个集合抽象级别，PointNet ++可以从局部几何结构中学习特征，并逐层抽象局部特征。
由于其简单性和强大的表示能力，已经基于PointNet [5]开发了许多网络。 Achlioptas等[28]介绍了一种深度自动编码器网络来学习点云表示。它的编码器遵循PointNet的设计，并使用五个1-D卷积层，ReLU非线性激活，批处理规范化和最大池化操作独立学习点特征。在点注意力变换（PAT）[29]中，每个点都由其自身的绝对位置和相对于其邻居的相对位置表示。然后，使用组混洗注意力（GSA）来捕获点之间的关系，并开发了排列不变，可区分且可训练的端到端Gumbel子集采样（GSS）层来学习分层特征。 Mo-Net [30]的体系结构与PointNet [5]相似，但是它需要一组有限的矩作为其网络的输入。 PointWeb [31]也是基于PointNet ++构建的，它使用局部邻域的上下文来使用自适应特征调整（AFA）来改进点特征。段等。 [32]提出了一种结构关系网络（SRN）来学习使用MLP的不同局部结构之间的结构关系特征。 Lin等[33]通过为PointNet所学习的输入和函数空间构造查找表来加速推理过程。在中等机器上，与PointNet相比，ModelNet和ShapeNet数据集上的推理时间缩短了1.5毫秒，达到32倍。 SRINet [34]首先投影一个点云以获得旋转不变表示，然后利用基于PointNet的主干来提取全局特征，并利用基于图的聚合来提取局部特征。

### 2.2.2 基于卷积的网络
与在2D网格结构（例如图像）上定义的内核相比，由于点云的不规则性，难以为3D点云设计卷积内核。 根据卷积内核的类型，当前的3D卷积网络可以分为连续卷积网络和离散卷积网络，**如图4所示。**

![image-20200422231246035](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231247.png)

图4：一个点的局部邻居的连续和离散卷积的图示。（a）代表局部近邻区；（b）和（c）分别代表3D连续和离散卷积。
3D连续卷积网络。 这些方法在连续空间上定义卷积核，其中相邻点的权重与相对于中心点的空间分布有关。
3D卷积可以解释为给定子集的加权和。 MLP是学习权重的一种简单方法。 RS-Conv作为RS-CNN[35]的核心层，以某一点周围的局部子集作为输入，通过学习局部子集中的低层关系（如欧几里德距离和相对位置）到高层关系的映射，利用MLP实现卷积。 在[36]中，内核元素是在单位球体内随机选择的。 然后使用基于MLP的连续函数在内核元素的位置和点云之间建立关系。 在DensePoint [37]中，卷积定义为具有非线性激活器的单层感知器（SLP）。 通过串联所有先前层的特征以充分利用上下文信息来学习特征。
一些方法还使用现有算法来执行卷积。在PointConv [38]中，卷积定义为相对于重要性采样的连续3D卷积的蒙特卡洛估计。卷积核由加权函数（通过MLP层学习）和密度函数（通过核化密度估计和MLP层学习）组成。为了提高内存和计算效率，将3D卷积进一步简化为两个运算：矩阵乘法和2D卷积。使用相同的参数设置，其内存消耗可减少约64倍。在MCCNN [39]中，卷积被视为依赖样本密度函数（由MLP实现）的蒙特卡洛估计过程。然后使用泊松磁盘采样来构建点云层次结构。该卷积算子可用于在两种或多种采样方法之间执行卷积，并可处理变化的采样密度。在SpiderCNN [40]中，提出了SpiderConv来定义卷积，将卷积定义为在k个最近邻居上定义的阶跃函数和泰勒展开式的乘积。阶梯函数通过对局部测地距离进行编码来捕获粗略的几何形状，泰勒展开通过在立方体的顶点处插值任意值来捕获固有的局部几何变化。此外，还基于径向基函数为3D点云提出了卷积网络PCNN [41]。托马斯等[42]使用一组可学习的核点，为3D点云提出了刚性和可变形核点卷积（KPConv）运算符。
已经提出了几种方法来解决3D卷积网络面临的旋转等变问题。 Esteves等人[43]提出了一种以多值球面函数为输入的三维球面卷积神经网络（spheral CNN）来学习三维形状的旋转等变表示。通过在球形谐波域中使用锚点对频谱进行参数化来获得局部卷积滤波器。张量场网络[44]将点卷积运算定义为可学习的径向函数和球谐函数的乘积，球谐函数局部等价于点的三维旋转、平移和置换。[45]中的卷积是基于球面互相关定义的，并使用广义快速傅里叶变换（FFT）算法实现。基于PCNN，SPHNet [46]通过在体积函数的卷积过程中合并球谐函数内核来实现旋转不变性。 ConvPoint [47]将卷积核分为空间和特征部分。从单位球体中随机选择空间部分的位置，并通过简单的MLP学习加权函数。
为了加快计算速度，Flex-Convolution [48]将卷积核的权重定义为k个最近邻居上的标准标量积，可以使用CUDA对其进行加速。实验结果证明了它在具有较少参数和较低内存消耗的小型数据集上的竞争性能。
3D离散卷积网络。 这些方法在常规网格上定义卷积核，其中相邻点的权重与相对于中心点的偏移量有关。
华等[49]将非均匀的3D点云转换为均匀的网格，并在每个网格上定义了卷积核。与2D卷积不同（向每个像素分配权重），提出的3D内核将相同的权重分配给落入同一网格的所有点。对于给定点，从上一层计算位于同一网格上的所有相邻点的平均特征。然后，对所有网格的平均特征进行加权和求和，以生成当前图层的输出。 Lei等[50]通过将3D球形邻近区域划分为多个体积区域并将每个区域与可学习的加权矩阵相关联来定义球形卷积核。一个点的球形卷积核的输出由其相邻点的加权激活值平均值的非线性激活确定。在GeoConv [51]中，一个点及其相邻点之间的几何关系是基于六个基础显式建模的。沿基础每个方向的边缘特征根据相邻点的基础由可学习的矩阵独立加权。然后根据给定点及其相邻点形成的角度聚合这些与方向相关的特征。对于给定点，其当前层的特征定义为给定点的特征及其在上一层的相邻边缘特征的总和。 PointCNN [52]通过χ-conv转换（通过MLP实现）实现了置换不变性。通过将点特征插值到相邻的离散卷积核量坐标，Mao等人[53]提出了一个插值卷积算子InterpConv来测量输入点云和核重量坐标之间的几何关系。张等[54]提出了一个RIConv算子来实现旋转不变性，它以低层旋转不变几何特征作为输入，然后通过一种简单的分区方法将卷积变成一维。
A-CNN [55]通过围绕查询点每个环上的核大小围绕邻居数组循环定义环形卷积。A-CNN学习局部子集中的相邻点之间的关系。为了减少3D CNN的计算和存储成本，Kumawat等人[56]提出了一种基于3D短期傅里叶变换（STFT）的3D局部邻域中的相位提取整流局部相体积（ReLPV）块，STFT显着减少了参数数量。在SFCNN [57]中，将点云投影到具有对齐球坐标的规则二十面体网格上。然后，通过卷积-最大池-卷积结构对从球形晶格的顶点及其相邻像素连接的特征进行卷积。 SFCNN抵抗旋转和扰动。

### 2.2.3 基于图的网络
​		基于图的网络将点云中的每个点视为图的顶点，并基于每个点的邻居为图生成有向边。然后在空间或频谱域中进行特征学习[58]。一个典型的基于图的网络如图5所示。

![image-20200422231338603](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231340.png)													图5：基于图的网络的图示。

​		空间域中基于图的方法。 这些方法在空间域中定义操作（例如，卷积和池化）。具体来说，卷积通常是通过空间邻域上的MLP来实现的，而池化则是通过聚合每个点邻域的信息来产生一个新的粗化图。通常为每个顶点的特征分配坐标，激光强度或颜色，而通常为每个边缘的特征分配两个连接点之间的几何属性。
作为开创性的工作，Simonovsky等人[58]将每个点视为图的顶点，并通过有向边将每个顶点连接到其所有邻居。然后，使用滤波器生成网络（例如，MLP）提出了边缘条件卷积（ECC）。采用最大池化来聚集邻域信息，并基于VoxelGrid [59]算法实现图粗化。对于形状分类，卷积核池化时交错的。然后，根据全局平均池化和全连接层产生分类分数。在DGCNN[60]中，在特征空间中构造一个图，并在网络的每一层之后动态更新。作为EdgeConv的核心层，采用MLP作为每个边缘的特征学习函数，并对与每个点邻域相关的边缘特征进行信道对称聚集。此外，LDGCNN[61]移除了变换网络，并将DGCNN[60]中不同层的分层特征连接起来，以提高其性能并减小模式大小。本文还提出了一种端到端无监督的深度自编码网络（FoldingNet[62]），它使用矢量化的局部协方差矩阵和点坐标的级联作为输入。
​		Hassani等人受Inception [63]和DGCNN [60]的启发。 [64]提出了一种无监督的多任务自动编码器来学习点和形状特征。 编码器是基于多尺度图构造的。 解码器是使用三个非监督任务构造的，包括聚类，自我监督分类和重构，这些任务与多任务损失一起训练。 刘等[65]提出了一种基于图卷积的动态点集聚模块（DPAM），以将点集聚（采样，分组和池化）的过程简化为一个简单的步骤，该步骤通过将集聚矩阵与点特征矩阵相乘来实现。 基于PointNet架构，通过堆叠多个DPAM来构建分层学习架构。与PointNet ++的层次结构策略相比，DPAM在语义空间中动态挖掘点与聚集点之间的关系。
​		为了利用局部几何结构，KCNet [66]学习基于核相关的特征。 具体而言，将表征局部结构的几何类型的一组可学习点定义为内核。 然后，计算内核与给定点邻域之间的亲和力。 在G3D [67]中，卷积定义为邻接矩阵多项式的变体，池化定义为将Laplacian矩阵和顶点矩阵乘以一个粗化矩阵。 ClusterNet [68]利用严格旋转不变（RRI）模块提取每个点的旋转不变特征，并基于具有监督联系标准的无监督聚集层次聚类方法构建点云的层次结构[69]。 首先通过EdgeConv块学习每个子集群中的特征，然后通过最大池化聚合。
频谱域中基于图的方法。 这些方法将卷积定义为频谱滤波，这是通过将图上的信号与图拉普拉斯矩阵的特征向量相乘来实现的[70]。
为了应对高计算量和非局部化的挑战，Defferrard等人[71]提出了一个截断的切比雪夫多项式来近似频谱滤波。他们学习的特征图位于每个点的K跳邻居内。注意，特征向量是根据[70] [71]中的固定图拉普拉斯矩阵计算的。相反，RGCNN [72]通过将每个点与点云中的所有其他点连接来构造图，并更新每一层中的图拉普拉斯矩阵。为了使相邻顶点的特征更相似，在损失函数中添加了先验图信号平滑度。为了解决由多样的数据图拓扑引起的挑战，AGCN [73]中的SGC-LL层利用可学习的距离度量来参数化图上两个顶点之间的相似度。从图获得的邻接矩阵使用高斯核和学习距离进行归一化。冯等[74]提出了一个超图神经网络（HGNN），并通过在超图上应用谱卷积来建立一个超边缘卷积层。
前述方法在全图上运行。为了利用局部的结构信息，王等[75]提出了一个端到端的频谱卷积网络LocalSpecGCN来处理局部图（它是由k个最近的邻居构造而成的）。此方法不需要对图拉普拉斯矩阵和图粗化层次进行任何离线计算。在PointGCN [76]中，基于来自点云的k个最近邻居构建图，并使用高斯核对每个边进行加权。卷积滤波器在图谱域中定义为Chebyshev多项式。全局池化和多分辨率池化用于捕获点云的全局和局部特征。 Pan等[77]通过在谱域中的k个最近邻图上应用卷积来提出3DTINet。通过从相对的欧几里得距离和方向距离中学习，可以实现几何变换的不变性。

### 2.2.4 基于数据索引的网络
​		这些网络是根据不同的数据索引结构（例如octree和kd-tree）构建的。在这些方法中，点特征是沿着树从叶节点到根节点分层学习的。 Lei等[50]提出了一种使用球面卷积核的八叉树引导的CNN。网络的每一层都对应于八叉树的一层，并且在每一层都应用了球形卷积核。当前层中神经元的值确定为上一层中所有相关子节点的平均值。与基于octree的OctNet [23]不同，Kd-Net [78]是使用多个K-d树构建的，每个树在每次迭代时具有不同的分割方向。按照自下而上的方法，使用MLP根据非子节点的子代表示来计算非子节点的表示。根节点的特征（描述整个点云）最终被馈送到全连接层以预测分类得分。注意，Kd-Net根据节点的拆分类型在每个级别共享参数。3DContextNet [79]使用标准的平衡K-d树来实现特征学习和聚合。在每个级别上，首先通过MLP基于局部提示（该局部提示对局部区域中的点之间的相互依赖性进行建模）和全局上下文提示（其针对一个位置相对于所有其他位置的关系进行建模）来学习点特征。然后，使用MLP从非子节点的子节点计算其特征，并通过最大池化对其进行聚合。对于分类，重复上述过程直到获得根节点。
​		SO-Net网络的层次结构是通过执行点到节点k最近邻居搜索来构建的[80]。具体而言，修改后的置换不变自组织图（SOM）用于对点云的空间分布进行建模。通过一系列全连接层，从归一化的点到节点坐标中学习单个点的特征。 SOM中每个节点的特征是使用通道的最大池化从与此节点关联的点特征中提取的。然后使用类似于PointNet [5]的方法从节点特征中学习最终特征。与PointNet ++ [27]相比，SOM的层次结构效率更高，并且可以充分利用点云的空间分布。

### 2.2.5 其他网络
​		除上述方法外，还提出了许多其他方案。在3DmFV [82]中，将点云体素化为统一的3D网格，并根据在这些网格上定义的一组高斯混合模型的似然性来提取费舍尔向量。由于费舍尔向量的分量在所有点上求和，因此所得表示形式对点云的顺序，结构和大小不变。 RBFNet [86]通过聚集来自稀疏分布的径向基函数（RBF）内核的特征来显式地建模点的空间分布。 RBF特征提取层计算所有内核对每个点的响应，然后对内核位置和内核大小进行优化，以捕获训练期间各点的空间分布。与全连接层相比，RBF特征提取层可产生更多区分性特征，同时将参数数量减少几个数量级。赵等[85]提出了一种无监督的自动编码器3DPointCapsNet，用于3D点云的通用表示学习。在编码器阶段，首先将逐点MLP应用于点云以提取点独立特征，然后将其进一步馈送到多个独立卷积层中。然后，通过串联多个最大池学习特征图来提取全局潜在表示。基于无监督的动态路径，可以学习强大的代表性潜在胶囊。 Xie等人[81]从形状上下文描述符的构建中得到启发[89]，提出了一种新颖的ShapeContextNet体系结构，该方法通过将亲和点选择和紧凑的特征聚合结合在一起，并使用点积自关注[90]进行软对齐操作。为了解决3D点云中的噪声和遮挡问题，鲍勃科夫等人[91]将基于手工制作的点对函数的4D旋转不变描述符输入4D卷积神经网络。 Prokudin等[92]首先从单位球中随机采样具有均匀分布的基点集，然后将点云编码为到基点集的最小距离，这将点云转换为固定长度相对较小的向量。然后可以使用现有的机器学习方法来处理编码的表示。RCNet [88]利用标准的RNN和2D CNN构造用于3D点云处理的置换不变网络。首先将点云划分为平行波束，并沿特定维度分类，然后将每个波束馈入共享的RNN。所学习的特征被进一步馈送到有效的2D CNN中以进行分层特征聚合。为了增强其描述能力，RCNet-E沿不同分区和排序方向集成多个RCNet。Point2Sequences [87]是另一个基于RNN的模型，可捕获点云局部区域中不同区域之间的相关性。它将从多个区域的局部区域中学习的特征视为序列，并将来自所有局部区域的这些序列馈送到基于RNN的编码器-解码器结构中，以聚合局部区域特征。秦等[93]提出了一种基于端到端无监督域自适应的网络PointDAN，用于3D点云表示。为了获取点云的语义特性，提出了一种自监督的点云重构方法，该方法对点云的部分进行了随机重组[94]。
​		还提出了几种方法来从3D点云和2D图像中学习。在PVNet [83]中，从多视图图像中提取的高级全局特征通过嵌入网络投影到点云的子空间中，并通过软关注掩模与点云特征融合。最后，对融合特征和多视图特征采用残差连接以执行形状识别。后来，进一步提出了PVRNet [84]，以利用3D点云及其多个视图之间的关系，这些关系是通过关系评分模块学习的。基于关系得分，原始的2D全局视图特征得到了增强，可用于点单视图融合和点多视图融合。
​		ModelNet10 / 40数据集是最常用的形状分类数据集。表1显示了通过不同的基于点的网络获得的结果。可以得出以下几点结论：

- 逐点MLP网络通常用作其他类型的网络的基本构建块，以学习逐点特征。

- 作为标准的深度学习架构，基于卷积的网络可以在不规则的3D点云上实现出色的性能。对于不规则数据，应该更加注意离散卷积网络和连续卷积网络。

- 由于其固有的强大能力来处理不规则数据，基于图形的网络近年来引起了越来越多的关注。但是，将频谱域中的基于图的网络扩展到各种图结构仍然具有挑战性。

- 大多数网络需要将点云降采样为固定的小尺寸。此采样过程将丢弃形状的详细信息。 开发可以处理大规模点云的网络仍处于起步阶段[95]。

  

  表1：ModelNet10/40基准上的比较3D形状分类结果。这里，我们只关注基于点的网络，“#params”指的是相应模型的参数个数。“OA”表示总体精度，“MACC”表示表中的平均精度。符号‘-’表示结果不可用。

![image-20200422231639901](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231641.png)

# 3 3D目标检测和跟踪

在这一部分中，我们将回顾现有的3D对象检测、3D对象跟踪和3D场景流量估计方法。

## 3.1 3D对象检测
3D对象检测的任务是在给定场景中准确定位所有感兴趣的对象。类似于图像中的对象检测[96]，3D对象检测方法可分为两类：基于区域提议的方法和single shot方法。**图6**展示了几种里程碑方法。

![image-20200422231809269](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231810.png)

图6：按时间顺序概述的最相关的基于深度学习的3D对象检测方法。

### 3.1.1 基于区域提案的方法
这些方法首先提议几个包含对象的可能区域（也称为提议），然后提取区域特征来确定每个提议的类别标签。根据其对象提案生成方法，这些方法可以进一步分为三类：基于多视图，基于分割和基于视锥的方法。
多视图方法。 这些方法融合了来自不同视图的建议性特征（例如，LiDAR前视图，鸟瞰图（BEV）和图像）以获得3D旋转框，**如图7（a）**所示。这些方法的计算成本通常很高。
Chen等。 [4]从BEV地图中生成了一组高度精确的3D候选框，并将其投影到多个视图的特征图（例如LiDAR前视图图像，RGB图像）。然后，他们将这些从不同视图获得的区域特征进行组合，以预测定向的3D边界框，**如图7**（a）所示。尽管此方法在只有300个提议的情况下以0.25的交叉路口（IoU）召回率达到99.1％，但对于实际应用而言，它的速度仍然太慢。随后，从两个方面开发了几种方法来改进多视图3D对象检测方法。
首先，已经提出了几种方法来有效地融合不同模态的信息。为了生成对小物体具有较高召回率的3D建议，Ku等人[97]提出了一种基于多模式融合的区域提议网络。他们首先使用裁剪和调整大小操作从BEV和图像视图中提取大小相等的特征，然后使用逐元素均值合并融合这些特征。梁等[98]利用连续卷积来实现图像和3D LiDAR特征图在不同分辨率下的有效融合。具体来说，他们为BEV空间中的每个点提取了最接近的对应图像特征，然后使用双线性插值法将图像特征投影到BEV平面中以获得密集的BEV特征图。实验结果表明，密集的BEV特征图比离散图像特征图和稀疏LiDAR特征图更适合3D对象检测。梁等[99]提出了一种用于端到端训练的多任务多传感器3D对象检测网络。具体而言，可以利用多种任务（例如2D目标检测，地面估计和深度补全）来帮助网络学习更好的特征表示。进一步利用学习到的跨模态表示来产生高度准确的对象检测结果。实验结果表明，该方法在2D，3D和BEV检测任务上取得了显着改进，并且优于TOR4D基准[100]，[101]上的最新技术。
其次，已经研究了不同的方法来提取输入数据的鲁棒表示。 Lu等。 [102]通过引入空间通道注意力（SCA）模块探索了多尺度上下文信息，该模块捕获了场景的全局和多尺度上下文并突出了有用的特征。他们还提出了扩展空间非采样（ESU）模块，通过组合多尺度低层特征来获得具有丰富空间信息的高层特征，从而生成可靠的3D对象建议。尽管可以实现更好的检测性能，但是上述多视图方法需要较长的运行时间，因为它们为每个建议执行特征池化。随后，Zeng等人[103]使用pre-RoI池化卷积来提高[4]的效率。具体来说，他们将大多数卷积运算移到了RoI池化模块的前面。因此，RoI卷积对于所有对象建议都执行一次。实验结果表明，该方法可以11.1 fps的速度运行，是MV3D的5倍[4]。

![image-20200422231859163](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231901.png)

![image-20200422231920436](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231922.png)

![image-20200422231939384](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422231941.png)

图7：三类3D对象检测方法的典型网络。 从上到下：（a）基于多视图的（b）基于分割的方法和（c）基于视锥的方法。
**基于分割的方法。** 这些方法首先利用现有的语义分割技术来去除大多数背景点，然后在前景点上生成大量高质量的建议以节省计算量，如图7（b）所示。与多视图方法[4]，[97]，[103]相比，这些方法实现了更高的对象召回率，并且更适合于对象被高度遮挡和拥挤的复杂场景。
杨等。 [104]使用2D分割网络来预测前景像素，并将其投影到点云中以去除大多数背景点。然后，他们在预测的前景点上生成提案，并设计了一个名为PointsIoU的新标准，以减少提案的冗余性和歧义性。继[104]之后，Shi等人[105]提出了一个PointRCNN框架。具体来说，他们直接分割3D点云以获得前景点，然后融合语义特征和局部空间特征以生成高质量3D框。继[105]的RPN阶段之后，Jesus等人[106]提出了一项开拓性的工作，以利用图卷积网络（GCN）进行3D对象检测。具体来说，引入了两个模块以使用图卷积来完善对象建议。第一个模块R-GCN利用提案中包含的所有点来实现按提案的特征聚合。第二个模块C-GCN将所有提案中的每帧信息融合在一起，以通过利用上下文来回归准确的对象框。 Sourabh等[107]将点云投影到基于图像的分割网络的输出中，并将语义预测分数附加到这些点上。将绘制的点馈送到现有的检测器[105]，[108]，[109]中，以实现显着的性能改进。杨等[110]将每个点与球形锚点关联。然后，使用每个点的语义评分来删除多余的锚点。因此，与先前的方法[104]，[105]相比，该方法以较低的计算成本实现了更高的召回率。另外，提出了一个PointsPool层来学习提议中内部点的紧凑特征，并引入了一个并行的IoU分支来提高定位精度和检测性能。实验结果表明，该方法在KITTI数据集[10]的困难集（汽车类）上明显优于其他方法[99]，[105]，[111]，并且以12.5 fps的速度运行。
基于视锥的方法。 这些方法首先利用现有的2D对象检测器生成对象的2D候选区域，然后为每个2D候选区域提取3D视锥提案，如图7（c）所示。尽管这些方法可以有效地建议3D对象的可能位置，但分步流水操作使其性能受到2D图像检测器的限制。
F-PointNets [112]是这个方向的开拓性工作。它为每个2D区域生成一个视锥提案，并应用PointNet [5]（或PointNet ++ [27]）来学习每个3D视锥的点云特征，以进行模态3D框估计。在后续工作中，Zhao等人。 [113]提出了一种Point-SENet模块来预测一组比例因子，这些比例因子还用于自适应地突出显示有用的特征并抑制信息量少的特征。他们还将PointSIFT [114]模块集成到网络中以捕获点云的方向信息，从而获得了强大的形状缩放鲁棒性。与F-PointNets [112]相比，该方法在室内和室外数据集[10] [115]上均取得了显着改善。
徐等[116]利用2D图像区域及其对应的平截头体点来精确地回归3D框。为了融合点云的图像特征和全局特征，他们提出了用于框角位置直接回归的全局融合网络。他们还提出了一个密集的融合网络，用于预测每个角的逐点偏移。 Shin等[117]首先从2D图像中估计对象的2D边界框和3D姿势，然后提取多个在几何上可行的对象候选对象。这些3D候选对象被输入到框回归网络中，以预测准确的3D对象框。 Wang等[111]沿着截头圆锥体轴为每个2D区域生成了一系列截头圆锥体，并应用PointNet [5]为每个截头圆锥体提取特征。对视锥级别的特征进行了重新生成以生成2D特征图，然后将其输入到完全卷积的网络中以进行3D框估计。该方法在基于2D图像的方法中达到了最先进的性能，并在官方KITTI排行榜中排名第一。 Lehner等[118]首先在BEV图上获得了初步的检测结果，然后根据BEV预测提取了小点子集（也称为图块）。应用局部优化网络来学习图块的局部特征，以预测高度精确的3D边界框。
其他方法。 得益于轴对齐IoU在图像目标检测中的成功，Zhou等人[119]将两个3D旋转边界框的IoU集成到几个最先进的检测器[105]，[109]，[120]中，以实现一致的性能改进。 Chen等[121]提出了一个两阶段的网络架构，以同时使用点云和体素表示。首先，将点云体素化并馈入3D骨干网络以产生初始检测结果。第二，进一步利用初始预测的内点特征来进行box优化。尽管此设计从概念上讲很简单，但在保持16.7 fps速度的同时，可达到与PointRCNN [105]相当的性能。
受基于Hough投票的2D对象检测器的启发，Qi等[122]提出了VoteNet直接对点云中对象的虚拟中心点进行投票的方法，并通过汇总投票特征来生成一组高质量的3D对象建议。 VoteNet仅使用几何信息就大大优于以前的方法，并在两个大型室内基准（即ScanNet [8]和SUN RGB-D [115]）上实现了最先进的性能。但是，对于部分遮挡的对象，虚拟中心点的预测是不稳定的。此外，冯等[123]添加了方向矢量的辅助分支，以提高虚拟中心点和3D候选框的预测精度。此外，构建提案之间的3D对象-对象关系图以强调用于精确对象检测的有用特征。 Shi等人的发现启发了3D对象的地面真相框提供对象内部零件的准确位置。 [124]提出了P art A2网络，它由部分感知阶段和部分聚集阶段组成。零件感知阶段使用具有稀疏卷积和稀疏反卷积的类UNet网络来学习点状特征，以预测和粗略生成对象内零件位置。零件汇总阶段采用RoI感知池来汇总预测零件的位置，以进行box评分和位置优化。

### 3.1.2 single-shot方法
这些方法使用单阶段网络直接预测类概率并回归对象的3D边界框。这些方法不需要区域提议的生成和后处理。结果，它们可以高速运行，非常适合实时应用。根据输入数据的类型，单次拍摄方法可分为两类：基于BEV的方法和基于点云的方法。
基于BEV的方法。 这些方法主要以BEV表示为输入。杨等[100]离散化了具有等距像元的场景的点云，并以类似的方式对反射率进行编码，从而得到规则的表示。然后，使用完全卷积网络（FCN）来估计对象的位置和航向角。这种方法在以28.6 fps的速度运行时，胜过大多数single-shot方法（包括VeloFCN [125]，3D-FCN [126]和Vote3Deep [127]）。后来，杨等人[128]利用高清（HD）映射提供的几何和语义先验信息来提高[100]的鲁棒性和检测性能。具体来说，他们从HD地图中获取了地面点的坐标，然后用相对于地面的距离替换了BEV表示中的绝对距离，以弥补由道路坡度引起的平移差异。此外，他们沿通道维度将二进制路面掩模与BEV表示连接起来，以专注于移动物体。由于高清地图并非随处可用，因此他们还提出了在线地图预测模块，以从单个LiDAR点云中估计地图先验。该地图感知方法在TOR4D [100]，[101]和KITTI [10]数据集上明显优于其基线。但是，其针对不同密度的点云的泛化性能很差。为了解决这个问题，Beltran等人[129]提出了一个归一化图来考虑不同LiDAR传感器之间的差异。归一化图是具有与BEV图相同的分辨率的2D网格，它对每个单元中包含的最大点数进行编码。结果表明，该归一化图显着提高了基于BEV的检测器的归纳能力。
基于点云的方法。 这些方法将点云转换为常规表示形式（例如2D地图），然后应用CNN预测对象的类别和3D框。
Li等[125]提出了使用FCN进行3D对象检测的第一种方法。他们将点云转换为2D点图，并使用2D FCN预测对象的边界框和置信度。后来，他们[126]将点云离散为具有长度，宽度，高度和通道尺寸的4D张量，并将基于2D FCN的检测技术扩展到3D域以进行3D对象检测。与[125]相比，基于3D FCN的方法[126]获得的准确度超过20％以上，但是由于3D卷积和数据稀疏性，不可避免地要花费更多的计算资源。为了解决体素的稀疏性问题，Engelcke等人[127]利用以特征为中心的投票方案为每个非空体素生成一组投票，并通过累积投票获得卷积结果。它的计算复杂度方法与所占用体素的数量成正比。 Li等[130]通过堆叠多个稀疏3D CNN构造了3D骨干网络。此方法旨在通过充分利用体素的稀疏性来节省内存并加速计算。这个3D骨干网络提取了丰富的3D特征用于对象检测，而不会带来繁重的计算负担。
周等[108]提出了一种基于体素的端到端可训练框架VoxelNet。他们将点云划分为等距的体素，并将每个体素中的要素编码为4D张量。然后连接区域提议网络以产生检测结果。尽管其性能强，但由于体素稀疏和3D卷积，该方法非常慢。后来，Yan等[120]使用稀疏卷积网络[134]来提高[108]的推理效率。他们还提出了正弦误差角损失，以解决0和π方向之间的歧义。 Sindagi等[131]通过在早期融合图像和点云特征来扩展VoxelNet。具体来说，他们将[108]生成的非空体素投影到图像中，并使用预训练网络为每个投影体素提取图像特征。然后将这些图像特征与体素特征连接在一起，以生成准确的3D框。与[108]，[120]相比，该方法可以有效地利用多模式信息来减少误报。 Lang等[109]提出了一种名为PointPillars的3D对象检测器。这种方法利用PointNet [5]来学习垂直列（柱）中组织的点云的特征，并将学习到的特征编码为伪图像。然后将2D对象检测管线应用于预测3D边界框。就平均精度（AP）而言，PointPillars优于大多数融合方法（包括MV3D [4]，RoarNet [117]和AVOD [97]）。而且，PointPillars在3D和BEV KITTI [10]基准上均可以62 fps的速度运行，使其非常适合实际应用。
**其他方法。** Meyer等[132]提出了一种称为LaserNet的高效3D对象检测器。该方法预测每个点在边界框上的概率分布，然后组合这些每点分布以生成最终的3D对象框。此外，将点云的密集范围视图（RV）表示用作输入，并提出了一种快速均值漂移算法来减少按点预测所产生的噪声。 LaserNet在0至50米的范围内实现了最先进的性能，其运行时间大大低于现有方法。 Meyer等[133]然后扩展LaserNet以利用RGB图像（例如50至70米）提供的密集纹理。具体来说，他们通过将3D点云投影到2D图像上来将LiDAR点与图像像素相关联，并利用这种关联将RGB信息融合到3D点中。他们还认为3D语义分割是学习更好的表示形式的辅助任务。该方法在远程（例如50至70米）目标检测和语义分割方面均实现了显着改进，同时保持了LaserNet的高效率[132]。

表2：Kitti测试3D检测基准上的3D对象检测结果比较。3D边界框欠条阈值对于汽车为0.7，对于行人和骑自行车者为0.5。模态为LiDAR(L)和IMAGE(I)。“E”、“M”和“H”分别代表易、中、难三类物体。为简单起见，我们省略了值后的‘%’。符号‘-’表示结果不可用。

![image-20200422232046618](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422232048.png)

表3：Kitti测试Bev检测基准上的3D对象检测结果比较。3D边界框欠条阈值对于汽车为0.7，对于行人和骑自行车者为0.5。模态为LiDAR(L)和IMAGE(I)。“E”、“M”和“H”分别代表易、中、难三类物体。为简单起见，我们省略了值后的‘%’。符号‘-’表示结果不可用。

![image-20200422232303350](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422232306.png)

## 3.2 3D对象跟踪

​		给定对象在第一帧中的位置，对象跟踪的任务是估计其在后续帧中的状态[135]，[136]。由于3D对象跟踪可以使用点云中的丰富几何信息，因此有望克服基于2D图像的跟踪所面临的一些缺点，包括遮挡，照明和比例变化。
​		受到基于图像的对象跟踪的孪生网络[137]的启发，Giancola等人[138]提出了一种具有形状补全规则化的3D孪生网络。具体来说，他们首先使用卡尔曼滤波器生成候选，然后使用形状正则化将模型和候选编码为紧凑的表示形式。余弦相似度然后用于在下一帧中搜索被跟踪对象的位置。这种方法可以用作对象跟踪的替代方法，并且明显优于大多数2D对象跟踪方法，包括Staple CA [139]和SiamFC [137]。为了有效地搜索目标物体，Zarzar等人[140]利用2D孪生网络在BEV表示上生成大量的粗略候选对象。然后，他们通过利用3D孪生网络中的余弦相似度来优化候选。这种方法在精度（即18％）和成功率（即12％）方面均明显优于[138]。西蒙等[141]提出了一种语义点云的3D对象检测和跟踪架构。他们首先通过融合2D视觉语义信息生成体素化的语义点云，然后利用时间信息来提高多目标跟踪的准确性和鲁棒性。此外，他们引入了功能强大且简化的评估指标（即“标度-旋转-翻译分数（SRF）”），以加快训练和推理速度。他们提出的Complexer-YOLO提出了有希望的跟踪性能，并且仍然可以实时运行。

## 3.3 3D场景流估计
​		类似于二维视觉中的光流估计，已经有几种方法开始从点云序列中学习有用的信息(如三维场景流、空间临时信息)。刘等人。[142]提出了直接从一对连续点云中学习场景流的FlowNet3D算法。FlowNet3D通过流嵌入层学习点级特征和运动特征。但是，FlowNet3D有两个问题。首先，一些预测的运动矢量在它们的方向上与地面真实有很大的不同。其次，FlowNet很难应用于非静态场景，特别是对于以变形体为主的场景。为了解决这一问题，王等人提出了解决方案。[143]引入余弦距离损失以最小化预测与地面事实之间的角度。此外，他们还提出了点到面的距离损失，以提高刚性和动态场景的精度。实验结果表明，这两个损失项将FlowNet3D的准确率从57.85%提高到63.43%，加快和稳定了训练过程。gu等人。[144]提出了一种基于层次置换面体格子流网(HPLFlowNet)的大规模点云场景流量直接估计方法。提出了几个双边卷积层来恢复原始点云的结构信息，同时降低了计算量。

​		为了有效地处理序列点云，Fan和Yang[145]提出了PointRNN、PointGRU和PointLSTM网络，并提出了一种序列到序列模型来跟踪移动点。PointRNN、PointGRU和PointLSTM能够捕获空间临时信息并对动态点云进行建模。类似地，Liu  et  al.。[146]提出了直接从动态点云中学习表示的气象网。该方法学习从时空邻近点聚集信息。进一步引入直接分组法和链流分组法来确定时间邻域。然而，上述方法的性能受到数据集规模的限制。Mittal等人。[147]提出了两个自监督损失，用于在大型未标记数据集上训练它们的网络。他们的主要思想是一种稳健的场景流量估计方法应该在向前和向后预测中都有效。由于场景流注释的不可用，预测变换点的最近邻域被认为是伪地真实。然而，真实的地面真相可能与最近的点不同。为了避免这个问题，他们计算了反向的场景流，并提出了循环一致性损失来将点平移到原始位置。实验结果表明，这种自监督方法的性能优于基于监督学习的方法。





## 3.4 总结



KITTI [10]基准是自动驾驶中最具影响力的数据集之一，已在学术界和工业界普遍使用。表2和表3分别显示了在KITTI 3D和BEV基准测试中，不同检测器所获得的结果。可以观察到以下几点：

- 基于区域提议的方法是这两种方法中研究最频繁的方法，并且在KITTI 3D测试和BEV基准测试中都大大优于单发方法。
- 现有的3D对象检测器有两个限制。首先，现有方法的远程检测能力相对较差。其次，如何充分利用图像中的纹理信息仍然是一个未解决的问题。
- 多任务学习是3D对象检测的未来方向。例如，MMF [99]学习了一种跨模态表示，通过合并多个任务来实现最新的检测性能。
- 3D对象跟踪和场景流估计是新兴的研究主题，自2019年以来逐渐吸引了越来越多的关注。



# 4 3D 点云分割
​		3D点云分割需要了解全局几何结构和每个点的细粒度细节。根据分割粒度，可以将3D点云分割方法分为三类：语义分割（场景级别），实例分割（对象级别）和部件分割（部件级别）。

## 4.1 3D 语义分割
​		在给定点云的情况下，语义分割的目标是根据点云的语义将点云划分为多个子集。类似于3D形状分类的分类(见第2节)，语义分割有两种范例，即基于投影的方法和基于点的方法。我们在图8中展示了几种有代表性的方法。



### 4.1.1基于投影的网络

​		如图9所示，中间规则表示可以被组织或分类为多视图表示[148]、[149]、球形表示[150]、[151]、[152]、体积表示[153]、[154]、[155]、置换面体网格表示[156]、[157]和混合表示[158]、[159]。

![image-20200422182105917](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422182109.png)

![image-20200429101823100](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200429101824.png)		

**多视图表示。**Felix等人。[148]首先将3D点云从多个虚拟相机视图投影到2D平面。然后，使用多流FCN对合成图像进行像素级分数预测。通过融合不同视图上的重新投影分数来获得每个点的最终语义标签。类似地，Boulch等人。[149]首先使用多个相机位置生成点云的多个RGB和深度快照。他们然后使用2D分割网络对这些快照进行像素级标记。使用残差校正进一步融合从RGB和深度图像预测的分数[160]。基于点云是从局部欧几里得曲面采样的假设，Tatarchenko等人。[161]引入了用于密集点云分割的切线卷积。此方法首先将每个点周围的局部曲面几何体投影到虚拟切线平面。然后直接在曲面几何体上操作切线卷积。该方法具有很强的可扩展性，能够处理几百万个点的大规模点云。总体而言，多视图分割方法的性能对视点选择和遮挡非常敏感。此外，这些方法没有充分利用底层的几何和结构信息，因为投影步骤不可避免地会引入信息损失。

![image-20200422182339274](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422182341.png)

**球面表示法（Spherical Representation）。**为了实现三维点云的快速准确分割，Wu等人提出了一种新的分割方法。[150]提出了一种基于SqueezeNet[162]和条件随机场(CRF)的端到端网络。为了进一步提高分割精度，引入了SqueezeSegV2[151]，通过使用无监督的域自适应流水线来解决域偏移问题。Milioto等人。[152]提出了基于RangeNet++的激光雷达点云实时语义分割方法。首先将二维深度图像的语义标签转换为三维点云，然后采用一种高效的基于GPU的基于KNN的后处理步骤来缓解离散化误差和推理输出模糊的问题。与单视图投影相比，球面投影保留了更多的信息，适合于激光雷达点云的标注。然而，这种中间表示不可避免地带来了离散化误差和遮挡等问题。

**体素表示法（Volumetric Representation）。**黄等人。[163]首先将点云划分为一组占用体素。然后，他们将这些中间数据提供给全3D卷积神经网络进行体素分割。最后，为体素内的所有点分配与体素相同的语义标签。该方法的性能受到体素粒度和点云分割引起的边界伪影的严重限制。此外，Tchapmi  et  al.。[164]提出SEGCloud实现细粒度、全局一致的语义分割。该方法引入确定性的三线性插值，将3D-FCNN[165]生成的粗体素预测映射回点云，然后使用完全连通CRF(FCCRF)来强制这些推断的每个点标签的空间一致性。孟等人。[153]提出了一种基于核的插值变分自动编码器结构，对每个体素内部的局部几何结构进行编码。代替二进制占用表示，对每个体素使用RBF来获得连续的表示并捕捉每个体素中的点的分布。VAE进一步用于将每个体素内的点分布映射到紧凑的潜在空间。然后，使用对称群和等价CNN来实现鲁棒的特征学习。

​		良好的可扩展性是体积表示的显著优势之一。具体地说，基于体积的网络可以在不同空间大小的点云中自由训练和测试。在全卷积点网络(FCPN)[154]中，首先从点云中分层提取不同层次的几何关系，然后使用3D卷积和加权平均汇集来提取特征并合并远程依赖关系。该方法可以处理大规模的点云数据，并且在推理过程中具有良好的可扩展性。Angela等人。[166]提出ScanComplete来实现3D扫描完成和每体素语义标注。该方法利用了全卷积神经网络的可扩展性并且能够在训练和测试过程中适应不同的输入数据大小。采用由粗到精的策略分层提高预测结果的分辨率。

​		体积表示自然是稀疏的，因为非零值的数量只占很小的百分比。因此，在空间稀疏数据上应用密集卷积神经网络效率不高。为此，Graham  et  al.。[155]提出子流形稀疏卷积网络。该方法通过将卷积的输出限制为仅与占用的体素相关，从而显著降低了存储和计算成本。同时，其稀疏卷积还可以控制提取特征的稀疏性。此子流形稀疏卷积适用于高维和空间稀疏数据的有效处理。此外，Choy  et al.。[167]提出了一种用于三维视频感知的4D时空卷积神经网络Minkowski  Net。为了有效地处理高维数据，提出了一种广义稀疏卷积算法。进一步应用一个三边平稳的条件随机场来加强一致性。

​		总体而言，体积表示自然保留了三维点云的邻域结构。其常规数据格式还允许直接应用标准3D卷积。这些因素导致了该领域性能的稳步提高。然而，体素化步骤固有地引入了离散化伪影和信息丢失。通常，高分辨率会导致较高的内存和计算成本，而较低的分辨率会导致细节丢失。在实践中，选择合适的网格分辨率并不是一件容易的事。

**Permutohedral Lattice Representation.** Su等[156]提出了基于双边卷积层（BCL）的稀疏格子网络（SPLATNet）。该方法首先将原始点云插值到四面体的稀疏晶格，然后将BCL应用于在稀疏填充的晶格的占据部分进行卷积。然后将滤波后的输出内插回原始点云。另外，该方法允许灵活地联合处理多视图图像和点云。此外，Rosu等 [157]提出了LatticeNet来实现大点云的有效处理。还引入了称为DeformsSlice的与数据相关的插值模块，以将晶格特征反投影到点云。

**Hybrid Representation.** 为了进一步利用所有可用信息，已经提出了几种方法来从3D扫描中学习多模式特征。 Angela和Matthias [158]提出了一个联合3D多视图网络，以结合RGB特征和几何特征。使用3D CNN流和几个2D流来提取特征，并提出了一个可微的反投影层，以联合融合学习到的2D嵌入和3D几何特征。此外，洪等。 **[168]提出了一个基于点的统一框架，以从点云中学习2D纹理外观，3D结构和全局上下文特征。该方法直接应用基于点的网络从稀疏采样的点集中提取局部几何特征和全局上下文，而无需任何体素化。** Jaritz等[159]提出了Multiview PointNet（MVPNet）来聚合2D多视图图像的外观特征和规范点云空间中的空间几何特征。



### 4.1.2基于点的网络

​		基于点的网络直接作用于不规则的点云。然而，点云是无序的、无结构的，直接应用标准的CNN是不可行的。为此，开创性工作PointNet[5]被提出使用共享MLP学习逐点特征和使用对称池化函数学习全局特征。基PointNet，最近提出了一系列基于点的网络。总的来说，这些方法大致可以分为逐点MLP方法、点卷积方法、基于RNN的方法和基于图的方法。

​		**逐点MLP方法。**这些方法通常使用共享MLP作为其网络的基本单元，因为其效率很高。然而，共享MLP提取的逐点特征不能捕获点云中的局部几何图形以及点之间的相互作用[5]。为了获取每个点更广泛的上下文和学习更丰富的局部结构，已经引入了几种专用网络，包括基于相邻特征池的方法、基于注意力的聚集方法和局部-全局特征拼接方法。

![image-20200422183747055](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422183749.png)

**相邻特征池：**为了捕获局部几何模式，这些方法通过聚合局部邻近点的信息来学习每个点的特征。特别地，PointNet++[27]从更大的局部区域中分层渐进地对点进行分组，如图10所示。还提出了**多尺度分组**和**多分辨率分组**来克服**点云的不均匀性和密度变化带来的问题**。后来，江等人。[114]提出了一种PointSIFT模块来实现**方向编码和尺度感知**。该模块通过三级有序卷积运算对来自八个空间方向的信息进行堆叠和编码。提取并拼接多尺度特征，实现对不同尺度的自适应。与PointNet++中使用的分组技术(即球查询)不同，Francis等人。[169]利用K-均值聚类和KNN分别定义世界空间和学习特征空间中的两个邻域。基于同类点在特征空间中的距离期望更近的假设，引入成对距离损失和质心损失，进一步规范了特征学习。为了模拟不同点之间的相互作用，赵等人。[31]提出了PointWeb，通过密集构建局部全链接网络来探索局部区域内所有点对之间的关系。提出了一种自适应特征调整(AFA)模块来实现信息交换和特征**细化。该聚合操作帮助网络学习区别性特征表示。**张某等人。[170]基于同心球壳的统计数据，提出了一种称为Shellconv的置换不变卷积。该方法首先查询一组多尺度同心球体，然后在不同的壳体内进行最大合并操作进行统计，最后利用MLP和一维卷积得到最终的卷积输出。Hu等人。[95]提出了一种高效轻量级的大规模点云处理网络**RandLA-Net**。该网络采用随机点采样，在存储和计算方面取得了显着的效率。在此基础上，提出了一个**局部特征聚合模块**来捕获和保存几何特征。

**基于注意力的聚合：**为了进一步提高分割精度，在点云分割中引入了注意力机制[90]。Yang等人。[29]提出了一种群体注意力转移方法来建模点之间的关系，并提出了一种置换不变、任务无关、可微的Gumbel子集抽样(GSS)来代替广泛使用的最远点抽样(FPS)方法。该模块对异常值不太敏感，并且可以选择具有代表性的点子集。为了更好地捕捉点云的空间分布，Chen等人。[171]提出了一种基于点云空间布局和局部结构的局部空间感知层(LSA)来学习空间感知权重。与CRF相似，赵等人。**<font color='red'>[172]提出了一种基于注意力的分数细化(ASR)模块，对网络产生的分割结果进行后处理。初始分割结果通过将相邻点的分数与学习的关注度权重汇集在一起来改进。该模块可以很容易地集成到现有的深度网络中，以提高最终的分割性能。 </font>**

**局部-整体串联**：赵等人。[85]提出了一种结合点云局部结构和全局背景的置换不变PS2网。Edgeconv[60]和NetVLAD[173]被重复堆叠以**捕捉局部信息和场景级全局特征**。

​		**点卷积法。**这些方法往往建议对点云进行有效的卷积运算。华等人。[49]提出了一种逐点卷积算子，将相邻的点合并到核细胞中，然后与核权值进行卷积。Wang等人。[174]提出了一种基于参数连续卷积层的PCCN网络。该层的核函数由MLP参数化，横跨连续向量空间。Hughes  et  al.。[42]提出了一种基于核点卷积(KPConv)的核点全卷积网络(KP-FCNN)。具体地说，KPConv的卷积权值是由到核点的欧几里德距离确定的，核点的个数是不固定的。将核点的位置表示为球空间中的最优复盖优化问题。值得注意的是，半径邻域被用来保持一致的接受场，而在每一层中使用网格子采样来实现对不同密度的点云的高鲁棒性。**<font color='red'>在[175]中，Francis  et  al.。提供了丰富的烧蚀实验和可视化结果，展示了感受场对基于聚集的方法性能的影响。他们还提出了一种膨胀点卷积(DPC)操作来聚集膨胀的相邻特征，而不是K个最近邻域。该操作被证明在增加接受范围方面非常有效，并且可以很容易地集成到现有的基于聚合的网络中。</font>**

​		**基于RNN的方法。**为了从点云中获取固有的上下文特征，递归神经网络(RNN)也被用于点云的语义分割。基于PointNet[5]，Francis  et  al.。[180]首先将点块变换为多尺度块和网格块，以获得输入级上下文。然后，将PointNet提取的分块特征依次送入合并单元(CU)或循环合并单元(RCU)，以获得输出级上下文。实验结果表明，**结合空间上下文对于提高分割性能具有重要意义。**黄等人。**[179]提出了一种轻量级局部依赖建模模型，并利用切片池层将无序的点特征集转换为有序的特征向量序列。**叶等人。[181]首先提出了点状金字塔汇集(3P)模型来捕捉由粗到细的局部结构，然后利用双向层次RNN进一步获取远程空间依赖关系。然后应用RNN实现端到端的学习。然而，当将局部邻域特征与全局结构特征聚合时，这些方法会丢失丰富的点云几何特征和密度分布[189]。为了缓解刚性和静态池化操作带来的问题，赵等人提出了解决方案。[189]提出了一种综合考虑全局场景复杂性和局部几何特征的动态聚合网络(DAR-NET)。使用自适应接受域和节点权重动态聚集中间特征。刘等人。**[190]提出了3DCNN-DQN-RNN用于高效的大规模点云语义解析。该网络首先利用三维CNN网络学习类对象的空间分布和颜色特征，然后利用DQN对类对象进行定位。将最终的级联特征向量送入残差RNN，得到最终的分割结果。**

**基于图的方法。****为了捕捉三维点云的基本形状和几何结构**，有几种方法求助于图形网络。Loic等人。[182]将点云表示为一组相互关联的简单形状和超点，并使用属性有向图(即超点图)来捕捉结构和上下文信息。然后，**将大规模点云分割问题分解为几何均匀分割、超点嵌入和上下文分割三个子问题。**为了进一步改进划分步骤，Loic和Mohamed[183]提出了一个监督框架，将点云过度分割为纯超点。该问题被描述为一个由邻接图构造的深度度量学习问题。此外，还提出了一种图形结构的对比损失，以帮助**识别物体之间的边界**。

​		为了更好地捕捉**高维空间中的局部几何关系**，Kang等人提出了一种新的方法。[191]提出了一种基于图嵌入模块(GEM)和金字塔注意力网络(PAN)的PyramNet。GEM模块将点云表示为有向无环图，并用协方差矩阵代替欧几里德距离构造相邻相似度矩阵。PAN模块使用四种不同大小的卷积核来提取不同语义强度的特征。在[184]中，**<font color='red'>图注意卷积(GAC)被提出用来从局部相邻集合中选择性地学习相关特征。该操作是通过基于不同的邻近点和特征通道的空间位置和特征差异动态地分配关注度权重来实现的。GAC可以学习获取可区分的特征进行分割，并且与常用的CRF模型具有相似的特征。</font>**

表4：在S3DIS(包括Area5和6折交叉验证)[176]、Semanc3D(包括语义-8和精简-8子集)[9]、ScanNet[8]和SemancKITTI[177]数据集上的比较语义分割结果。综合精度(OA)、并集平均交集(MIUU)是主要的评价指标。为简单起见，我们省略了值后的‘%’。符号‘-’表示结果不可用。

![image-20200422223318339](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422223321.png)

## 4.2 实例分割

与语义分割相比，实例分割更具挑战性，因为它需要更精确、更细粒度的点推理。特别是，它不仅需要区分语义不同的点，还需要区分语义相同的实例。总体而言，现有的方法可以分为两类：基于提案的方法和无提案的方法。图11中说明了几种里程碑式的方法。

![image-20200422223507833](https://cdn.jsdelivr.net/gh/lizhangjie316/img/2020/20200422223510.png)

4.2.1 Proposal-based Methods（基于提案的方法）

​		这些方法将实例分割问题转化为两个子任务：三维对象检测和实例掩码预测。侯等人。[192]提出了一种3D全卷积语义实例分割(3D-SIS)网络来实现RGBD扫描的语义实例分割。该网络同时从颜色和几何特征中学习。类似于3D对象检测，3D区域建议网络(3D-RPN)和3D区域间(3D-ROI)层被用来预测边界框位置、对象类别标签和实例掩码。遵循综合分析的策略，Yi  et  al.。[193]提出了一种生成式形状建议书网络(GSPN)来生成高客观性的三维建议书。这些建议由基于区域的PointNet(R-PointNet)进一步完善。通过预测每个类别标签的逐点二进制掩码来获得最终标签。与直接从点云数据回归三维边界框不同，该方法通过加强几何理解，去除了大量无意义的建议。通过将2D全景分割扩展到3D映射，Gaku等人。[194]为实现大规模三维重建、语义标注和实例分割，提出了一种在线三维映射系统。他们首先利用2D语义和实例分割网络来获得像素级的全景标签，然后将这些标签整合到体积地图上。进一步使用全连接的CRF来实现准确的分割。该语义映射系统能够实现高质量的语义映射和区分对象识别。Yang等人。[195]提出了一种单级、无锚点、端到端的可训练网络3D-Bonet来实现点云实例分割。该方法直接回归所有潜在实例的粗略3D包围盒，然后利用点级二值分类器获得实例标签。特别地，将包围盒生成任务表示为最优分配问题。此外。提出了一种多准则损失函数对生成的包围盒进行正则化。该方法不需要任何后处理，计算效率高。张某等人。[196]提出了一种用于大规模室外LiDAR点云分割的网络模型。该方法使用自关注块来学习点云鸟瞰视图上的特征表示。根据预测的水平中心和高度限制获得最终的实例标签。

​		总体而言，基于提案的方法直观、直观，实例分割结果具有较好的客观性。然而，这些方法需要多阶段训练和修剪多余的建议。因此，它们通常既耗时又计算昂贵。

4.2.2 Proposal-free Methods（4.2.2免提案方法）

​		无建议方法[197]、[198]、[199]、[200]、[201]、[202]没有对象检测模块。相反，他们通常认为实例分割是语义分割之后的后续聚类步骤。特别地，现有的大多数方法都基于这样的假设，即属于同一实例的点应该具有非常相似的特征。因此，这些方法主要集中在鉴别特征学习和点分组两个方面。

​		在一个开创性的工作中，王等人。[197]首先介绍了相似群体提案网络(SGPN)。该方法首先为每个点学习一个特征和语义图，然后引入一个相似度矩阵来表示每个特征对之间的相似度。为了学习更具区分性的特征，他们使用双铰链损失来相互调整相似度矩阵和语义分割结果。最后，采用启发式非最大抑制方法将相似点合并成实例。由于相似矩阵的构造需要较大的内存消耗，限制了该方法的可扩展性。类似地，Liu  et  al.。[201]首先杠杆子流形稀疏卷积[155]以预测每个体素的语义分数和相邻体素之间的亲和度。然后，他们引入了一种聚类算法，根据预测的亲和度和网格拓扑将点分组为实例。此外，梁等人还提出了一些新的结论。[202]提出了一种用于区分嵌入学习的结构感知损失。这种损失既考虑了特征的相似性，又考虑了点之间的几何关系。基于注意力的图CNN被进一步用于通过聚合来自邻居的不同信息来自适应地提炼学习的特征。

​		由于点的语义类别和实例标签通常是相互依赖的，因此已经提出了几种将这两个任务耦合到单个任务中的方法。Wang等人。[198]通过引入端到端且可学习的关联分段实例和语义(ASIS)模块，将这两项任务集成在一起。实验表明，通过该ASIS模块，语义特征和实例特征可以相互支持，提高性能。同样，Pham等人也是如此。[199]首先引入了多任务点式网络(MT-PNET)来为每个点分配标签，并通过引入区分损失来规则化特征空间中的嵌入[203]。然后，他们将预测的语义标签和嵌入融合到多值条件随机场(MV-CRF)模型中进行联合优化。最后，利用平均场变分推理产生语义标签和实例标签。Hu等人。[204]首先提出了一种动态区域生长(DRG)方法，将点云动态分割成一组不相交的面片，然后使用无监督K-Means++算法对所有面片进行分组。然后在面片间的上下文信息的指导下进行多尺度的面片分割。最后，将这些带标签的块合并到对象层，得到最终的语义和实例标签。

​		为了实现全3D场景下的实例分割，Cathrin等人提出了一种基于三维场景的实例分割方法。[200]提出了一种2D-3D混合网络，用于从BEV表示和点云的局部几何特征中联合学习全局一致的实例特征。然后将学习到的特征组合以实现语义和实例分割。注意，不是使用启发式GroupMerging算法[197]，而是使用更灵活的MeanShift[205]算法来将这些点分组为实例。另外，对于实例分割，还引入了多任务学习。Jean等人。[206]学习了每个实例的唯一特征嵌入和指向对象中心的方向信息。提出了特征嵌入损失和方向损失的概念，以调整潜在特征空间中的学习特征嵌入。采用MeanShift聚类和非最大值抑制将体素分组为实例。该方法在ScanNet[8]基准上实现了最先进的性能。此外，预测的方向信息对于确定实例边界特别有用。张某等人。[207]将概率嵌入引入点云实例分割。该方法还引入了不确定性估计，并为聚类步骤提出了一个新的损失函数。

​		总之，从计算方面讲，无提案方法不需要昂贵的区域建议组件。然而，由这些方法分组的实例效果较低，因为这些方法不明显地检测对象边界。

## 4.3 零件分割

​		三维形状部分分割的难度是双重的。首先，具有相同语义标签的形状零件具有较大的几何变异和歧义。其次，该方法应对噪声和采样具有鲁棒性。

​		VoxSegNet[208]的提出是为了在有限的解决方案下实现对3D体素数据的细粒度分割。提出了一种空间密集提取(SDE)模块(由堆叠的ATHROS残差块组成)，用于从稀疏体数据中提取多尺度可分辨特征。通过逐步应用注意力特征聚集(AFA)模块，进一步对学习的特征进行重新加权和融合。Evangelos等人。[209]将FCN和基于曲面的CRF相结合，实现端到端的3D零件分割。他们首先从多个视图生成图像，以实现最优的表面覆盖，然后将这些图像馈送到2D网络中，以生成置信度图。然后，这些置信度图由基于曲面的CRF聚合，该CRF负责对整个场景进行一致的标记。Yi等人的研究成果。[210]介绍了一种同步谱CNN(SyncSpecCNN)算法，用于对不规则、非同构形状的图形进行卷积运算。引入膨胀卷积核的谱参数化和谱变换网络，解决了局部多尺度分析和形状间信息共享的问题。Wang等人。

​		[211]首先引入形状全卷积网络(SFCN)，以3个低层几何特征作为输入，对三维网格进行形状分割。然后，他们利用基于投票的多标签图切割来进一步细化分割结果。朱等人。[212]提出了一种用于三维形状共分割的弱监督CoSegNet算法。该网络将未分割的三维点云形状集合作为输入，通过迭代最小化组一致性损失来产生形状部分标签。类似于CRF，提出了一个预先训练的零件求精网络来进一步细化和去噪零件建议。Chen等人。[213]提出了一种分支自动编码器网络(BAE-Net)，用于无监督、单镜头和弱监督的三维形状共分割。该方法将形状共分割问题描述为一个表示学习问题，目的是通过最小化形状重构损失来寻找最简单的零件表示。基于编解码器体系结构，该网络的每个分支可以学习特定零件形状的紧凑表示。然后，从每个分支学习的特征和点坐标被馈送到解码器以产生二进制值(其指示点是否属于该部分)。该方法具有较好的泛化能力，可以处理大的三维形状集合(多达5000多个形状)。但是，该方法对初始参数敏感，没有将形状语义融入到网络中，阻碍了该方法在每次迭代中获得稳健稳定的估计。



## 4.4 总结

表4显示了现有方法在公共基准上取得的结果，包括S3DIS[176]、Semanti3D[9]、ScanNet[102]和SemancKITTI[177]。需要进一步研究的问题有以下几个：

- 基于点的网络是研究最多的方法。然而，点表示自然没有显式的邻域信息，现有的大多数基于点的方法不得不求助于昂贵的邻域搜索机制(例如，KNN[52]或Ball  Query[27])。这固有地限制了这些方法的效率，因为邻居搜索机制需要高计算成本和不规则的存储器访问[214]。·
- 从不平衡数据中学习仍然是点云分割中的一个具有挑战性的问题。虽然有几种方法[42]、[170]、[182]取得了显著的整体表现，但它们在少数群体类上的表现仍然有限。例如，RandLA-Net[95]在语义3D的精简8子集上实现了76.0%的总体IOU，但在硬件类上的IOU非常低，只有41.1%。
- ·现有的大多数方法[5]、[27]、[52]、[170]、[171]适用于小的点云(例如，具有4096个点的1M×1M)。在实际应用中，深度传感器获取的点云数据通常是巨大的、大规模的。因此，需要进一步研究大规模点云的高效分割问题。
- ·一些工作[145]、[146]、[167]已经开始从动态点云中学习时空信息。期望时空信息能够帮助提高后续任务(如3D对象识别、分割和完成)的性能。

# 5 总结

综述了三维理解方法的研究现状，包括三维形状分类、三维目标检测与跟踪、三维场景与目标分割等。对这些方法进行了全面的分类和性能比较。文中还介绍了各种方法的优缺点，并指出了可能的研究方向。

# REFERENCES
